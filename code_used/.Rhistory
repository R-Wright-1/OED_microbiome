plt.xlabel('Confidence threshold')
#else: plt.xticks([float(conf) for conf in confidence], ['' for conf in confidence])
plt.xlim([-0.025, 1.025])
if metric in limits_all: plt.ylim(limits[metric])
elif metric in prec_rec_f1: plt.ylim([-0.05, 1.05])
plt.ylabel(y_labels[metric])
if m == 1:
plt.yscale('symlog')
if metric in prec_rec_f1 or metric == 'Proportion classified':
max_value = max([abs(val) for val in overall])
max_index = [abs(val) for val in overall].index(max_value)
max_value = overall[max_index]
string = 'Maximum = '+str(round(max_value, 3))+'\nat confidence\nthreshold '+confidence[max_index]
else:
min_value = min([abs(val) for val in overall])
min_index = [abs(val) for val in overall].index(min_value)
min_value = overall[min_index]
string = 'Minimum = '+str(round(min_value, 3))+'\nat confidence\nthreshold '+confidence[min_index]
if metric in alpha_div and metric != 'Proportion classified': string = string.replace('Minimum = ', 'Absolute minimum =\n').replace('\nat confidence', ' at confidence')
anchored_text = AnchoredText(string, loc=locations[metric])
ax.add_artist(anchored_text)
plt.tight_layout()
#plt.subplots_adjust(hspace=5)
plt.savefig(direc_save+'figures/RefSeqV205_confidence_alpha_diversity_metrics_lines.png', dpi=600, bbox_inches='tight')
plt.figure(figsize=(34,20))
all_dbs = ['kraken2_minikraken', 'kraken2_standard_0521', 'kraken2_chocophlan', 'kraken2_refseqV205_100GB', 'kraken2_refseqV208_nt', 'kraken2_refseqV205_500GB', 'kraken2_GTDBr202RefSeqV205', 'kraken2_refseqV205']
truth_calcs = pd.read_csv(direc_save+'truth_calculations.csv', index_col=0, header=0)
limited_metrics = ['Proportion classified', 'Number of taxa', 'Mean F1 score', "Shannon diversity", 'L1 distance']
limited_limits = {'Proportion classified':[-0.05, 1.05], 'Mean F1 score':[0, 0.9], "Shannon diversity":[-2, 1], 'L1 distance':[400000, 16000000]}
limited_locations = ['upper right', 'lower left', 'lower left', 'upper right', 'lower left', 'upper right', 'lower left', 'lower left',
'upper right', 'lower left', 'lower left', 'upper right', 'lower left', 'upper right', 'lower left', 'lower left',
'upper right', 'upper left', 'upper left', 'upper right', 'upper left', 'upper right', 'upper left', 'lower right',
'upper right', 'lower left', 'lower left', 'upper right', 'lower left', 'lower left', 'lower left', 'lower left',
'lower right', 'upper left', 'upper left', 'lower right', 'lower right', 'lower right', 'lower right', 'upper left']
count = 0
for metric in limited_metrics:
for db in all_dbs:
count += 1
ax = plt.subplot(5,8,count)
plt.sca(ax)
if db == 'kraken2_minikraken': plt.ylabel(metric.replace('Proportion classified', 'Proportion of reads classified').replace('Number of taxa', 'Number of species identified'), fontweight='bold')
if metric == 'Proportion classified': plt.title(rename_db[db].replace('Complete', '\nComplete').replace('archaea', 'archaea\n'), fontweight='bold')
if metric == 'L1 distance':
plt.xticks([float(conf) for conf in confidence], confidence, rotation=90)
plt.xlabel('Confidence threshold')
else: plt.xticks([float(conf) for conf in confidence], [])
this_db = pd.read_csv(direc_save+db+'_calculations.csv', index_col=0, header=0)
all_conf = [[] for conf in confidence]
for sample in samples:
this_sample = []
for c in range(len(confidence)):
conf = confidence[c]
try:
val = this_db.loc[sample+'-'+db+'-'+conf, metric]
except:
if metric in prec_rec_f1: val = 0
else: val = max(this_db.loc[:, metric].values)
if metric in alpha_div and metric not in ['Proportion classified']: val = val-truth_calcs.loc[sample, metric]
this_sample.append(val)
all_conf[c].append(val)
line = plt.plot([float(conf) for conf in confidence], this_sample, 'k', alpha=0.05)
overall, upper, lower = [], [], []
for b in range(len(all_conf)):
overall.append(np.median(all_conf[b]))
upper.append(np.percentile(all_conf[b], 75))
lower.append(np.percentile(all_conf[b], 25))
line = plt.plot([float(conf) for conf in confidence], overall, color='firebrick')
line = plt.fill_between([float(conf) for conf in confidence], upper, lower, color='firebrick', alpha=0.2)
if metric == 'Shannon diversity': line = plt.plot([float(confidence[0]), float(confidence[-1])], [0,0], 'k--')
if metric != 'Number of taxa':
#plt.ylim(limited_limits[metric])
plt.yscale('symlog')
if metric in prec_rec_f1 or metric == 'Proportion classified':
max_value = max([abs(val) for val in overall])
max_index = [abs(val) for val in overall].index(max_value)
max_value = overall[max_index]
string = 'Maximum = '+str(round(max_value, 3))+'\nat confidence\nthreshold '+confidence[max_index]
else:
min_value = min([abs(val) for val in overall])
min_index = [abs(val) for val in overall].index(min_value)
min_value = overall[min_index]
string = 'Minimum = '+str(round(min_value, 3))+'\nat confidence\nthreshold '+confidence[min_index]
if metric in alpha_div and metric != 'Proportion classified': string = string.replace('Minimum = ', 'Absolute minimum =\n').replace('\nat confidence', ' at confidence')
anchored_text = AnchoredText(string, loc=limited_locations[count-1])
ax.add_artist(anchored_text)
plt.savefig(direc_save+'figures/Databases_confidence_comparison_reduced_metrics.png', dpi=600, bbox_inches='tight')
plt.figure(figsize=(34,20))
all_dbs = ['kraken2_minikraken', 'kraken2_standard_0521', 'kraken2_chocophlan', 'kraken2_refseqV205_100GB', 'kraken2_refseqV208_nt', 'kraken2_refseqV205_500GB', 'kraken2_GTDBr202RefSeqV205', 'kraken2_refseqV205']
truth_calcs = pd.read_csv(direc_save+'truth_calculations.csv', index_col=0, header=0)
limited_metrics = ['Proportion classified', 'Number of taxa', 'Mean F1 score', "Shannon diversity", 'L1 distance']
limited_limits = {'Proportion classified':[-0.05, 1.05], 'Mean F1 score':[0, 0.9], "Shannon diversity":[-2, 1], 'L1 distance':[400000, 16000000]}
limited_locations = ['upper right', 'lower left', 'lower left', 'upper right', 'lower left', 'upper right', 'lower left', 'lower left',
'upper right', 'lower left', 'lower left', 'upper right', 'lower left', 'upper right', 'lower left', 'lower left',
'upper right', 'upper left', 'upper left', 'upper right', 'upper left', 'upper right', 'upper left', 'lower right',
'upper right', 'lower left', 'lower left', 'upper right', 'lower left', 'lower left', 'lower left', 'lower left',
'lower right', 'upper left', 'upper left', 'lower right', 'lower right', 'lower right', 'lower right', 'upper left']
count = 0
for metric in limited_metrics:
for db in all_dbs:
count += 1
ax = plt.subplot(5,8,count)
plt.sca(ax)
if db == 'kraken2_minikraken': plt.ylabel(metric.replace('Proportion classified', 'Proportion of reads classified').replace('Number of taxa', 'Number of species identified'), fontweight='bold')
if metric == 'Proportion classified': plt.title(rename_db[db].replace('Complete', '\nComplete').replace('archaea', 'archaea\n'), fontweight='bold')
if metric == 'L1 distance':
plt.xticks([float(conf) for conf in confidence], confidence, rotation=90)
plt.xlabel('Confidence threshold')
else: plt.xticks([float(conf) for conf in confidence], [])
this_db = pd.read_csv(direc_save+db+'_calculations.csv', index_col=0, header=0)
all_conf = [[] for conf in confidence]
for sample in samples:
this_sample = []
for c in range(len(confidence)):
conf = confidence[c]
try:
val = this_db.loc[sample+'-'+db+'-'+conf, metric]
except:
if metric in prec_rec_f1: val = 0
else: val = max(this_db.loc[:, metric].values)
if metric in alpha_div and metric not in ['Proportion classified']: val = val-truth_calcs.loc[sample, metric]
this_sample.append(val)
all_conf[c].append(val)
line = plt.plot([float(conf) for conf in confidence], this_sample, 'k', alpha=0.05)
overall, upper, lower = [], [], []
for b in range(len(all_conf)):
overall.append(np.median(all_conf[b]))
upper.append(np.percentile(all_conf[b], 75))
lower.append(np.percentile(all_conf[b], 25))
line = plt.plot([float(conf) for conf in confidence], overall, color='firebrick')
line = plt.fill_between([float(conf) for conf in confidence], upper, lower, color='firebrick', alpha=0.2)
if metric == 'Shannon diversity': line = plt.plot([float(confidence[0]), float(confidence[-1])], [0,0], 'k--')
if metric != 'Number of taxa':
plt.ylim(limited_limits[metric])
else:
plt.yscale('symlog')
if metric in prec_rec_f1 or metric == 'Proportion classified':
max_value = max([abs(val) for val in overall])
max_index = [abs(val) for val in overall].index(max_value)
max_value = overall[max_index]
string = 'Maximum = '+str(round(max_value, 3))+'\nat confidence\nthreshold '+confidence[max_index]
else:
min_value = min([abs(val) for val in overall])
min_index = [abs(val) for val in overall].index(min_value)
min_value = overall[min_index]
string = 'Minimum = '+str(round(min_value, 3))+'\nat confidence\nthreshold '+confidence[min_index]
if metric in alpha_div and metric != 'Proportion classified': string = string.replace('Minimum = ', 'Absolute minimum =\n').replace('\nat confidence', ' at confidence')
anchored_text = AnchoredText(string, loc=limited_locations[count-1])
ax.add_artist(anchored_text)
plt.savefig(direc_save+'figures/Databases_confidence_comparison_reduced_metrics.png', dpi=600, bbox_inches='tight')
plt.figure(figsize=(18,6))
limited_metrics = ['Proportion classified', 'Number of taxa', 'Mean F1 score', "Shannon diversity", 'L1 distance']
truth_calcs = pd.read_csv(direc_save+'truth_calculations.csv', index_col=0, header=0)
metaphlan = pd.read_csv(direc_save+'MetaPhlAn_calculations.csv', index_col=0, header=0)
refseq_V205 = pd.read_csv(direc_save+'kraken2_refseqV205_calculations.csv', index_col=0, header=0)
chocophlan = pd.read_csv(direc_save+'kraken2_chocophlan_calculations.csv', index_col=0, header=0)
settings = ['default', 'estimated_reads', 'bowtie2_reads', 'very_sensitive_local', 'sensitive', 'sensitive_local', 'avg_g', 'avg_l', 'tavg_l', 'wavg_g', 'wavg_l', 'med']
comp_dbs = [metaphlan, chocophlan, refseq_V205]
db_names = ['MetaPhlAn', 'kraken2_chocophlan', 'kraken2_refseqV205']
limits = [[-0.05, 1.05], [-1000, 15000], [-0.05, 0.85], [-1.5, 1.5], [400000, 20000000]]
plotting_db = [['estimated_reads', 'sensitive'], ['0.00', '0.25', '0.50', '0.85', '1.00'], ['0.00', '0.15', '0.50', '0.65', '1.00']]
labels = ['Estimated reads: very-sensitive', 'Estimated reads: sensitive', 'Confidence threshold=0.00', 'Confidence threshold=0.25', 'Confidence threshold=0.50', 'Confidence threshold=0.85', 'Confidence threshold=1.00', 'Confidence threshold=0.00', 'Confidence threshold=0.15', 'Confidence threshold=0.50', 'Confidence threshold=0.65', 'Confidence threshold=1.00']
xlabels = ['Proportion', 'Difference between classification\nand known composition', 'F1 score', 'Difference between classification\nand known composition', 'Distance between classification\nand known composition']
axes = []
for m in range(len(limited_metrics)):
metric = limited_metrics[m]
ax = plt.subplot(1,5,m+1)
plt.sca(ax)
axes.append(ax)
plt.title(metric.replace('Proportion classified', 'Proportion of reads classified').replace('Number of taxa', 'Number of species identified'), fontweight='bold')
medians = []
loc = 0
locs = []
for d in range(len(comp_dbs)):
db = comp_dbs[d]
for setting in plotting_db[d]:
this_db = []
for sample in samples:
try:
val = db.loc[sample+'-'+db_names[d]+'-'+setting, metric]
except:
val = 0
if metric in alpha_div or metric in beta_div and metric not in ['Proportion classified']:
if val == 0:
val = max(db.loc[:, metric].values)
if metric in alpha_div and metric not in ['Proportion classified']:
val = val-truth_calcs.loc[sample, metric]
#if metric in alpha_div: print(sample+'-'+db_names[d]+'-'+setting, val)
this_db.append(val)
scat = plt.scatter(this_db, np.random.normal(loc+1, scale=0.1, size=len(this_db)), s=10, alpha=0.1, color=colors_db[db_names[d]])
box = plt.boxplot(this_db, positions=[loc+1], showfliers=False, widths=0.5, vert=False)
for item in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']: lines = plt.setp(box[item], color='k')
med = np.median(this_db)
medians.append(med)
if abs(med) < 0.5: smed = str(round(med, 3))
elif abs(med) < 10: smed = str(round(med, 3))
elif abs(med) < 100: smed = str(round(med, 1))
else: smed = str(round(med))
pt = plt.text(med, loc+0.7, smed, ha='center', va='top')
if metric == "Shannon diversity": simps = plt.plot([0, 0], [0, loc+1.5], 'k--')
locs.append(loc+1)
loc += 1
loc += 1
if metric == 'Proportion classified':py = plt.yticks(locs, labels)
else: py = plt.yticks(locs, [])
px = plt.xlabel(xlabels[m])
px = plt.xlim(limits[m])
py = plt.ylim([0.25, loc-0.5])
plt.sca(axes[0])
plt.text(-1.05, 1.5, 'MetaPhlAn 3', ha='center', va='center', rotation=90, fontweight='bold')
plt.text(-1.05, 6, 'Kraken2\nChocoPhlAn 3', ha='center', va='center', rotation=90, fontweight='bold')
plt.text(-1.05, 12, 'Kraken2\nNCBI RefSeq Complete V205', ha='center', va='center', rotation=90, fontweight='bold')
plt.tight_layout()
plt.savefig(direc_save+'figures/metaphlan_vs_kraken_choco_v205_horizontal_reduced_metrics.png', dpi=600, bbox_inches='tight')
plt.figure(figsize=(18,6))
limited_metrics = ['Proportion classified', 'Number of taxa', 'Mean F1 score', "Shannon diversity", 'L1 distance']
truth_calcs = pd.read_csv(direc_save+'truth_calculations.csv', index_col=0, header=0)
metaphlan = pd.read_csv(direc_save+'MetaPhlAn_calculations.csv', index_col=0, header=0)
refseq_V205 = pd.read_csv(direc_save+'kraken2_refseqV205_calculations.csv', index_col=0, header=0)
chocophlan = pd.read_csv(direc_save+'kraken2_chocophlan_calculations.csv', index_col=0, header=0)
settings = ['default', 'estimated_reads', 'bowtie2_reads', 'very_sensitive_local', 'sensitive', 'sensitive_local', 'avg_g', 'avg_l', 'tavg_l', 'wavg_g', 'wavg_l', 'med']
comp_dbs = [metaphlan, chocophlan, refseq_V205]
db_names = ['MetaPhlAn', 'kraken2_chocophlan', 'kraken2_refseqV205']
limits = [[-0.05, 1.05], [-2000, 15000], [-0.05, 0.85], [-1.5, 1.5], [400000, 20000000]]
plotting_db = [['estimated_reads', 'sensitive'], ['0.00', '0.25', '0.50', '0.85', '1.00'], ['0.00', '0.15', '0.50', '0.65', '1.00']]
labels = ['Estimated reads: very-sensitive', 'Estimated reads: sensitive', 'Confidence threshold=0.00', 'Confidence threshold=0.25', 'Confidence threshold=0.50', 'Confidence threshold=0.85', 'Confidence threshold=1.00', 'Confidence threshold=0.00', 'Confidence threshold=0.15', 'Confidence threshold=0.50', 'Confidence threshold=0.65', 'Confidence threshold=1.00']
xlabels = ['Proportion', 'Difference between classification\nand known composition', 'F1 score', 'Difference between classification\nand known composition', 'Distance between classification\nand known composition']
axes = []
for m in range(len(limited_metrics)):
metric = limited_metrics[m]
ax = plt.subplot(1,5,m+1)
plt.sca(ax)
axes.append(ax)
plt.title(metric.replace('Proportion classified', 'Proportion of reads classified').replace('Number of taxa', 'Number of species identified'), fontweight='bold')
medians = []
loc = 0
locs = []
for d in range(len(comp_dbs)):
db = comp_dbs[d]
for setting in plotting_db[d]:
this_db = []
for sample in samples:
try:
val = db.loc[sample+'-'+db_names[d]+'-'+setting, metric]
except:
val = 0
if metric in alpha_div or metric in beta_div and metric not in ['Proportion classified']:
if val == 0:
val = max(db.loc[:, metric].values)
if metric in alpha_div and metric not in ['Proportion classified']:
val = val-truth_calcs.loc[sample, metric]
#if metric in alpha_div: print(sample+'-'+db_names[d]+'-'+setting, val)
this_db.append(val)
scat = plt.scatter(this_db, np.random.normal(loc+1, scale=0.1, size=len(this_db)), s=10, alpha=0.1, color=colors_db[db_names[d]])
box = plt.boxplot(this_db, positions=[loc+1], showfliers=False, widths=0.5, vert=False)
for item in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']: lines = plt.setp(box[item], color='k')
med = np.median(this_db)
medians.append(med)
if abs(med) < 0.5: smed = str(round(med, 3))
elif abs(med) < 10: smed = str(round(med, 3))
elif abs(med) < 100: smed = str(round(med, 1))
else: smed = str(round(med))
pt = plt.text(med, loc+0.7, smed, ha='center', va='top')
if metric == "Shannon diversity": simps = plt.plot([0, 0], [0, loc+1.5], 'k--')
locs.append(loc+1)
loc += 1
loc += 1
if metric == 'Proportion classified':py = plt.yticks(locs, labels)
else: py = plt.yticks(locs, [])
px = plt.xlabel(xlabels[m])
px = plt.xlim(limits[m])
py = plt.ylim([0.25, loc-0.5])
plt.sca(axes[0])
plt.text(-1.05, 1.5, 'MetaPhlAn 3', ha='center', va='center', rotation=90, fontweight='bold')
plt.text(-1.05, 6, 'Kraken2\nChocoPhlAn 3', ha='center', va='center', rotation=90, fontweight='bold')
plt.text(-1.05, 12, 'Kraken2\nNCBI RefSeq Complete V205', ha='center', va='center', rotation=90, fontweight='bold')
plt.tight_layout()
plt.savefig(direc_save+'figures/metaphlan_vs_kraken_choco_v205_horizontal_reduced_metrics.png', dpi=600, bbox_inches='tight')
limits_all = {"Simpson's diversity":[-0.1, 0.1], "Shannon diversity":[-1, 2], "Faith's phylogenetic diversity":[-1000, 15000], "Chao1 richness":[-1000, 11000], "McIntosh's evenness":[-0.1, 0.2], "Pielou evenness":[-0.3, 0.2], "Simpson's evenness": [-0.25, 0.25], "L1 distance":[-100, 20000000], "Robust Aitchisons distance":[-1, 40], "Bray-Curtis dissimilarity relative abundance":[-0.05, 1.05], "Weighted unifrac distance relative abundance":[-10, 300], "Unweighted unifrac distance relative abundance":[-0.05, 1.05], "Aitchisons distance":[-10, 250], "Bray-Curtis dissimilarity raw":[-0.05, 1.05], "Weighted unifrac distance raw":[-10, 175], "Unweighted unifrac distance raw":[-0.05, 1.05], 'Number of taxa':[-1000, 15000]}
plt.figure(figsize=(24,24))
all_metrics = prec_rec_f1+alpha_div+beta_div
truth_calcs = pd.read_csv(direc_save+'truth_calculations.csv', index_col=0, header=0)
metaphlan = pd.read_csv(direc_save+'MetaPhlAn_calculations.csv', index_col=0, header=0)
refseq_V205 = pd.read_csv(direc_save+'kraken2_refseqV205_calculations.csv', index_col=0, header=0)
chocophlan = pd.read_csv(direc_save+'kraken2_chocophlan_calculations.csv', index_col=0, header=0)
settings = ['default', 'estimated_reads', 'bowtie2_reads', 'very_sensitive_local', 'sensitive', 'sensitive_local', 'avg_g', 'avg_l', 'tavg_l', 'wavg_g', 'wavg_l', 'med']
comp_dbs = [metaphlan, chocophlan, refseq_V205]
db_names = ['MetaPhlAn', 'kraken2_chocophlan', 'kraken2_refseqV205']
limits = [[-0.05, 1.05], [-0.05, 0.85], [-0.05, 0.3], [400000, 20000000]]
location_single = ['lower left', 'lower right', 'upper right', 'upper right']
plotting_db = [['estimated_reads', 'sensitive'], ['0.00', '0.35', '0.50', '0.90', '1.00'], ['0.00', '0.15', '0.50', '0.60', '1.00']]
labels = ['Estimated reads: very-sensitive', 'Estimated reads: sensitive', 'Confidence threshold=0.00', 'Confidence threshold=0.35', 'Confidence threshold=0.50', 'Confidence threshold=0.90', 'Confidence threshold=1.00', 'Confidence threshold=0.00', 'Confidence threshold=0.15', 'Confidence threshold=0.50', 'Confidence threshold=0.60', 'Confidence threshold=1.00']
xlabels = ['Proportion', 'Score', 'Difference', 'Distance']
axes = []
for m in range(len(all_metrics)):
metric = all_metrics[m]
ax = plt.subplot(4,7,m+1)
plt.sca(ax)
axes.append(ax)
ttl = plt.title(metric.replace('Proportion classified', 'Proportion of\nreads classified').replace('relative abundance', '\nrelative abundance').replace('raw', '\nraw').replace('Number of taxa', 'Number of species\nidentified'), fontweight='bold')
medians = []
loc = 0
locs = []
for d in range(len(comp_dbs)):
db = comp_dbs[d]
for setting in plotting_db[d]:
this_db = []
for sample in samples:
try:
val = db.loc[sample+'-'+db_names[d]+'-'+setting, metric]
except:
val = 0
if metric in alpha_div or metric in beta_div and metric not in ['Proportion classified']:
if val == 0:
val = max(db.loc[:, metric].values)
if metric in alpha_div and metric not in ['Proportion classified']:
val = val-truth_calcs.loc[sample, metric]
#if metric in alpha_div: print(sample+'-'+db_names[d]+'-'+setting, val)
this_db.append(val)
scat = plt.scatter(this_db, np.random.normal(loc+1, scale=0.1, size=len(this_db)), s=10, alpha=0.1, color=colors_db[db_names[d]])
box = plt.boxplot(this_db, positions=[loc+1], showfliers=False, widths=0.5, vert=False)
for item in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']: lines = plt.setp(box[item], color='k')
med = np.median(this_db)
medians.append(med)
if abs(med) < 0.5: smed = str(round(med, 3))
elif abs(med) < 10: smed = str(round(med, 3))
elif abs(med) < 100: smed = str(round(med, 1))
else: smed = str(round(med))
pt = plt.text(med, loc+0.7, smed, ha='center', va='top')
if metric in alpha_div and metric not in ['Proportion classified', 'Number of taxa']: simps = plt.plot([0, 0], [0, loc+1.5], 'k--')
locs.append(loc+1)
loc += 1
loc += 1
if m % 7 == 0:
pt = plt.yticks(locs, labels)
pt = plt.text(-1.05, 0.09, 'MetaPhlAn 3', ha='center', va='center', rotation=90, fontweight='bold', transform=ax.transAxes)
pt = plt.text(-1.05, 0.39, 'Kraken2\nChocoPhlAn 3', ha='center', va='center', rotation=90, fontweight='bold', transform=ax.transAxes)
pt = plt.text(-1.05, 0.82, 'Kraken2\nNCBI RefSeq\nComplete V205', ha='center', va='center', rotation=90, fontweight='bold', transform=ax.transAxes)
else: yt = plt.yticks(locs, [])
if metric in limits_all:
pt = plt.xlim(limits_all[metric])
elif metric != 'Number of taxa': pt = plt.xlim([-0.05, 1.10])
pt = plt.ylim([0.25, loc-0.5])
#plt.tight_layout()
#plt.show()
plt.savefig(direc_save+'figures/metaphlan_vs_kraken_choco_v205_horizontal_all_metrics.png', dpi=600, bbox_inches='tight')
library(reticulate)
library(knitr)
conda_python(envname = 'r-reticulate', conda = "auto")
reticulate::repl_python()
folder = '/Users/robynwright/Documents/OneDrive/Langille_Lab_postdoc/microbiome_helper/silva_ltp_tree/'
myTree <- ape::read.tree(paste(folder, 'Tree_LTP_all_12_2021.ntree', sep=''))
#ape::write.tree(myTree, paste(folder, 'Tree_LTP_all_04_2021_R.ntree', sep=''))
labels = TreeTools::TipLabels(myTree)
install.packages('TreeTools')
library(reticulate)
library(knitr)
library(TreeTools)
library(ape)
folder = '/Users/robynwright/Documents/OneDrive/Langille_Lab_postdoc/microbiome_helper/silva_ltp_tree/'
myTree <- ape::read.tree(paste(folder, 'Tree_LTP_all_12_2021.ntree', sep=''))
#ape::write.tree(myTree, paste(folder, 'Tree_LTP_all_04_2021_R.ntree', sep=''))
labels = TreeTools::TipLabels(myTree)
length(labels)
labels[1:100]
reticulate::repl_python()
folder = '/Users/robynwright/Documents/OneDrive/Langille_Lab_postdoc/microbiome_helper/silva_ltp_tree/'
myTree <- ape::read.tree(paste(folder, 'Tree_LTP_all_12_2021.ntree', sep=''))
#ape::write.tree(myTree, paste(folder, 'Tree_LTP_all_04_2021_R.ntree', sep=''))
labels = TreeTools::TipLabels(myTree)
length(labels)
reticulate::repl_python()
options(warn = -1)
library(reticulate)
#library(kableExtra)
library(knitr)
library(ALDEx2)
install.packages('ALDEx2')
BiocManager::install("ALDEx2")
BiocManager::install("Maaslin2")
options(warn = -1)
library(reticulate)
#library(kableExtra)
library(knitr)
library(ALDEx2)
library(Maaslin2)
reticulate::repl_python()
options(warn = -1)
library(reticulate)
#library(kableExtra)
library(knitr)
library(ALDEx2)
library(Maaslin2)
reticulate::repl_python()
reticulate::repl_python()
library(reticulate)
#library(kableExtra)
library(knitr)
conda_python(envname = 'r-reticulate', conda = "auto")
reticulate::repl_python()
reticulate::repl_python()
library(shiny)
runGist("943ff5fdbd94815cc27f302d9f56ff0b")
runGist("943ff5fdbd94815cc27f302d9f56ff0b")
library(ape)
library(reticulate)
library(ALDEx2)
library(Maaslin2)
library(ape)
library("survminer")
# library(dplyr)
# library(exactRankTests)
# library(ggplot2)
# library(ggnewscale)
# library(nlme)
# library(philr)
library(phyloseq)
library(vegan)
library(tidyr)
# library(compositions)
conda_python(envname = 'r-reticulate', conda = "auto")
reticulate::repl_python()
for (a in 1:2) {
mat_df = as.data.frame(py$similarity_matrix[a])
mat = data.matrix(mat_df)
colnames(mat) = rownames(mat)
md = py$md
permanova <- adonis(mat_df ~ md$Progression*md$patient_age*md$sex*md$ethnicity_details*md$TotalWeeklyAlcoholUnits*md$smoking_status*md$diagnosis*md$anatomical_site, data=mat_df, strata=md$Group)
table = permanova$aov.tab
write.csv(table, paste(py$folder, 'diversity/permanova_', py$matrix_names[a], '.csv', sep=''))
}
for (a in 1:2) {
mat_df = as.data.frame(py$similarity_matrix[a])
mat = data.matrix(mat_df)
colnames(mat) = rownames(mat)
md = py$md
permanova <- adonis(mat_df ~ md$Time_to_progression_grouped*md$patient_age*md$sex*md$ethnicity_details*md$TotalWeeklyAlcoholUnits*md$smoking_status*md$diagnosis*md$anatomical_site, data=mat_df, strata=md$Group)
table = permanova$aov.tab
write.csv(table, paste(py$folder, 'diversity/permanova_grouped_', py$matrix_names[a], '.csv', sep=''))
}
reticulate::repl_python()
for (a in 1:2) {
mat_df = as.data.frame(py$similarity_matrix[a])
mat = data.matrix(mat_df)
colnames(mat) = rownames(mat)
md = py$md
permanova <- adonis(mat_df ~ md$Total_Number_of_Months_Followed_or_to_Progression*md$patient_age*md$sex*md$ethnicity_details*md$TotalWeeklyAlcoholUnits*md$smoking_status*md$diagnosis*md$anatomical_site, data=mat_df)
table = permanova$aov.tab
write.csv(table, paste(py$folder, 'diversity/permanova_progressors_', py$matrix_names[a], '.csv', sep=''))
}
for (a in 1:2) {
mat_df = as.data.frame(py$similarity_matrix[a])
mat = data.matrix(mat_df)
colnames(mat) = rownames(mat)
md = py$md
permanova <- adonis(mat_df ~ md$Time_to_progression_grouped*md$patient_age*md$sex*md$ethnicity_details*md$TotalWeeklyAlcoholUnits*md$smoking_status*md$diagnosis*md$anatomical_site, data=mat_df)
table = permanova$aov.tab
write.csv(table, paste(py$folder, 'diversity/permanova_progressors_grouped_', py$matrix_names[a], '.csv', sep=''))
}
reticulate::repl_python()
source(paste("/Users/robynwright/Dropbox/Langille_Lab_postdoc/Github/", "ancom_v2.1.R", sep=""))
ft = py$ft
md = py$md
md['Samples'] = row.names(md)
process = feature_table_pre_process(ft, md, 'Samples', 'Progression', lib_cut=10, neg_lb=TRUE)
ancom_out_all = ANCOM(process$feature_table, process$meta_data, main_var='Progression')
ancom_out_all = ancom_out_all$out
write.csv(ancom_out_all, paste(py$folder, "differential_abundance/ancom_EC.csv", sep=''))
reticulate::repl_python()
ft = py$ft
table_num = data.matrix(ft[,1:90]) #convert the ASV table to a numeric matric
rownames(table_num) = rownames(ft)
table = otu_table(table_num, taxa_are_rows = TRUE)
physeq = phyloseq(table)
physeq_rare <- rarefy_even_depth(physeq, sample.size = min(sample_sums(physeq)), replace = TRUE, trimOTUs = TRUE, verbose = TRUE)
table_rare = data.frame(otu_table(physeq_rare))
write.csv(table_rare, paste(py$folder, 'processing/pred_metagenome_unstrat_rare_R.csv', sep=''))
reticulate::repl_python()
ft = py$ft
table_num = data.matrix(ft[,1:90]) #convert the ASV table to a numeric matric
rownames(table_num) = rownames(ft)
table = otu_table(table_num, taxa_are_rows = TRUE)
physeq = phyloseq(table)
physeq_rare <- rarefy_even_depth(physeq, sample.size = min(sample_sums(physeq)), replace = TRUE, trimOTUs = TRUE, verbose = TRUE)
table_rare = data.frame(otu_table(physeq_rare))
write.csv(table_rare, paste(py$folder, 'processing/path_abun_unstrat_rare_R.csv', sep=''))
reticulate::repl_python()
ft = py$ft_rare
md = py$md
md['Samples'] = row.names(md)
#md = md[c('Samples', 'Progression')]
feat_table = data.frame(t(ft), check.rows = F, check.names = F, stringsAsFactors = F)
results_all <- Maaslin2(feat_table, md, paste(py$folder, "differential_abundance/maaslin_EC_full_model", sep=''), transform = "AST", fixed_effects = c("Progression"), random_effects=c("Group"), standardize = FALSE, plot_heatmap = F, plot_scatter = F, reference="Progression,NP")
ft = py$ft_rare
md = py$md
md['Samples'] = row.names(md)
#md = md[c('Samples', 'Progression')]
feat_table = data.frame(t(ft), check.rows = F, check.names = F, stringsAsFactors = F)
results_all <- Maaslin2(feat_table, md, paste(py$folder, "differential_abundance/maaslin_EC_grouped_full_model", sep=''), transform = "AST", fixed_effects = c("Time_to_progression_grouped"), random_effects=c("Group"), standardize = FALSE, plot_heatmap = F, plot_scatter = F, reference="Time_to_progression_grouped,NP")
source(paste("/Users/robynwright/Dropbox/Langille_Lab_postdoc/Github/", "ancom_v2.1.R", sep=""))
ft = py$ft
md = py$md
md['Samples'] = row.names(md)
process = feature_table_pre_process(ft, md, 'Samples', 'Time_to_progression_grouped', lib_cut=10, neg_lb=TRUE)
ancom_out_all = ANCOM(process$feature_table, process$meta_data, main_var='Time_to_progression_grouped')
ancom_out_all = ancom_out_all$out
write.csv(ancom_out_all, paste(py$folder, "differential_abundance/ancom_asv_grouped.csv", sep=''))
ft = py$ft
md = py$md
md['Samples'] = row.names(md)
md = md[c('Samples', 'Progression')]
results_all <- aldex(reads=ft, conditions = md[,2], mc.samples = 128, test="kw", effect=TRUE, include.sample.summary = FALSE, verbose=T, denom="all")
reticulate::repl_python()
